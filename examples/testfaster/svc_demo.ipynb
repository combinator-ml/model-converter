{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outstanding-dimension",
   "metadata": {},
   "source": [
    "# Containerizer service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-original",
   "metadata": {},
   "source": [
    "Import libraries that have been installed before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fa609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import modzymodel\n",
    "import mlflow\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-summary",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "This will train a sklearn model and it will be saved as a joblib file inside the `model` directory.\n",
    "\n",
    "The goal for containerizer service is to create an image that exposes this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "data = digits.images.reshape((len(digits.images), -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "dump(clf, './model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f23438",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap your model in a pyfunc and provide auxiliary functionality through extension of the\n",
    "# mlflow PythonModel class with methods pre_process, post_process, and explain\n",
    "\n",
    "class CustomModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        self.model = joblib.load(\"./model.joblib\")\n",
    "\n",
    "    def predict(self, context, inputs):\n",
    "        processed_inputs = self.pre_process(inputs)\n",
    "        inference_results = self.model.predict(processed_inputs)\n",
    "        return self.post_process(inference_results)\n",
    "\n",
    "    def pre_process(self, inputs):\n",
    "        return inputs / 2\n",
    "\n",
    "    def post_process(self, inference_results):\n",
    "        structured_results = []\n",
    "        for inference_result in inference_results:\n",
    "            inference_result = {\n",
    "                \"classPredictions\": [\n",
    "                    {\"class\": str(inference_result), \"score\": str(1)}\n",
    "                ]\n",
    "            }\n",
    "            structured_output = {\n",
    "                \"data\": {\n",
    "                    \"result\": inference_result,\n",
    "                    \"explanation\": None,\n",
    "                    \"drift\": None,\n",
    "                }\n",
    "            }\n",
    "            structured_results.append(structured_output)\n",
    "        return structured_results\n",
    "\n",
    "    def explain(self, images):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f74bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define conda environment with all required dependencies for your model\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\", \"conda-forge\", \"pytorch\"],\n",
    "    \"dependencies\": [\n",
    "        \"python=3.8.5\",\n",
    "        \"pytorch=1.8.1+cpu\",\n",
    "        \"torchvision=0.9.1+cpu\",\n",
    "        \"pip\",\n",
    "        {\n",
    "            \"pip\": [\n",
    "                \"mlflow\",\n",
    "                \"lime\",\n",
    "                \"sklearn\"\n",
    "                \"cloudpickle==1.6.0\",\n",
    "                \"opencv-python\"\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"linear_env\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cda6c",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "Transform the model into MLFlow format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "model_save_path = \"model/mlflow_custom_pyfunc_svm\"\n",
    "mlflow.pyfunc.save_model(path=model_save_path, python_model=CustomModel(), conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac440385",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = mlflow.pyfunc.load_model(model_save_path)\n",
    "predictions = classifier.predict(X_test)\n",
    "print(json.dumps(predictions[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-northern",
   "metadata": {},
   "source": [
    "We check that the model has been correctly saved inside the `model` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ac7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./model/mlflow_custom_pyfunc_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-brazil",
   "metadata": {},
   "source": [
    "### Define the values needed\n",
    "\n",
    "The fields `name`, `version` and `api_key` are used when uploading the image to Modzy platform.\n",
    "\n",
    "Since now we are just creating and downloading the docker image, the only fields that containerizer service actually needs are:\n",
    "\n",
    "* `model_name`: name for the model inside the image\n",
    "* `model_path`: directory that contains our model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'XXXX'\n",
    "\n",
    "image_data = {\n",
    "    'name': 'docker-registry:5000/mlflow-digits-containerized',\n",
    "    'version': '0.0.1',\n",
    "    'model_name': 'digits',\n",
    "    'model_path': './model/MLFlowModel',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-failing",
   "metadata": {},
   "source": [
    "### Launch the job\n",
    "\n",
    "Important fields that we should fill in here are:\n",
    "\n",
    "* `module`: library that has been used to create the model\n",
    "* `image_data`: the values defined above\n",
    "* `image_type`: this is needed in case we are training images so afterwards the proxy will know how to interpret data\n",
    "* `base_url`: the name of the service that runs the containerizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = modzymodel.publish(\n",
    "    api_key=api_key,\n",
    "    module=sklearn,\n",
    "    image_data=image_data,\n",
    "    deploy=True,\n",
    "    image_type=modzymodel.Constants.IMAGE_GREY,\n",
    "    base_url='http://containerizer:5000'\n",
    ")\n",
    "\n",
    "error = res.get('error')\n",
    "job_id = res.get('job_id')\n",
    "\n",
    "if error:\n",
    "    print('Error:', error)\n",
    "else:\n",
    "    print('Job ID:', job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-arrow",
   "metadata": {},
   "source": [
    "After the request is made, containerizer launches a job that runs Kaniko and builds the docker image based on the values provided.\n",
    "\n",
    "You can get the id of the job created from the result of the request. This id can be used to ask for the status of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "modzymodel.get_job_status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15304f",
   "metadata": {},
   "source": [
    "Now, we should be able to see the created image listed in the registry. This means that the service has correctly created the image and uploaded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9df1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- http://docker-registry:5000/v2/_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-prison",
   "metadata": {},
   "source": [
    "### Download the tar file\n",
    "\n",
    "Now that the job has finished, we can download the docker image that has been generated in the form of a tar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = './downloaded_image.tar'\n",
    "modzymodel.download_tar(job_id, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, FileLink\n",
    "\n",
    "local_file = FileLink(dst, result_html_prefix=\"Click here to download: \")\n",
    "display(local_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}