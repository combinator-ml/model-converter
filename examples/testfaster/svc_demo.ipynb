{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outstanding-dimension",
   "metadata": {},
   "source": [
    "# Chassis.ml demo\n",
    "\n",
    "## Easily build MLflow models into {KFServing, Modzy} Docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-original",
   "metadata": {},
   "source": [
    "This demo will show you how we can train a model, define custom pre- and post-processing steps, save it in MLflow format and then build it into a container image and push it to docker hub with a single command.\n",
    "\n",
    "By easily connecting MLflow models to Docker images with a simple Python SDK for data scientists & ML engineers, Chassis is the missing link between MLflow and DevOps.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* [Docker Hub](https://hub.docker.com/) account (free one is fine)\n",
    "* The browser you're reading this in :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fa609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import sklearn\n",
    "import mlflow.pyfunc\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-summary",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "This will train a sklearn model and it will be saved as a joblib file inside the `model` directory.\n",
    "\n",
    "The goal for Chassis service is to create an image that exposes this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "data = digits.images.reshape((len(digits.images), -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "dump(clf, './model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f23438",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap your model in a pyfunc and provide auxiliary functionality through extension of the\n",
    "# mlflow PythonModel class with methods pre_process, post_process, and explain\n",
    "\n",
    "class CustomModel(mlflow.pyfunc.PythonModel):\n",
    "    _model = load('./model.joblib')\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        self.model = self._model\n",
    "\n",
    "    def predict(self, context, inputs):\n",
    "        processed_inputs = self.pre_process(inputs)\n",
    "        inference_results = self.model.predict(processed_inputs)\n",
    "        return self.post_process(inference_results)\n",
    "\n",
    "    def pre_process(self, inputs):\n",
    "        return inputs / 2\n",
    "\n",
    "    def post_process(self, inference_results):\n",
    "        structured_results = []\n",
    "        for inference_result in inference_results:\n",
    "            inference_result = {\n",
    "                \"classPredictions\": [\n",
    "                    {\"class\": str(inference_result), \"score\": str(1)}\n",
    "                ]\n",
    "            }\n",
    "            structured_output = {\n",
    "                \"data\": {\n",
    "                    \"result\": inference_result,\n",
    "                    \"explanation\": None,\n",
    "                    \"drift\": None,\n",
    "                }\n",
    "            }\n",
    "            structured_results.append(structured_output)\n",
    "        return structured_results\n",
    "\n",
    "    def explain(self, images):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f74bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define conda environment with all required dependencies for your model\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\", \"conda-forge\", \"pytorch\"],\n",
    "    \"dependencies\": [\n",
    "        \"python=3.8.5\",\n",
    "        \"pytorch\",\n",
    "        \"torchvision\",\n",
    "        \"pip\",\n",
    "        {\n",
    "            \"pip\": [\n",
    "                \"mlflow\",\n",
    "                \"lime\",\n",
    "                \"sklearn\"\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"linear_env\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cda6c",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "Transform the model into MLFlow format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf mlflow_custom_pyfunc_svm\n",
    "model_save_path = \"mlflow_custom_pyfunc_svm\"\n",
    "mlflow.pyfunc.save_model(path=model_save_path, python_model=CustomModel(), conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c819be5",
   "metadata": {},
   "source": [
    "Load the MLFlow model and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac440385",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "classifier = mlflow.pyfunc.load_model(model_save_path)\n",
    "predictions = classifier.predict(X_test)\n",
    "print(json.dumps(predictions[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-northern",
   "metadata": {},
   "source": [
    "We check that the model has been correctly saved inside the `model` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ac7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./mlflow_custom_pyfunc_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-brazil",
   "metadata": {},
   "source": [
    "### Get Docker Hub credentials securely\n",
    "\n",
    "Now we prompt the user (you!) for your docker hub username and password in such a way that the value itself doesn't get written into the notebook, which is sensible security best-practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import base64\n",
    "username = getpass.getpass(\"docker hub username\")\n",
    "password = getpass.getpass(\"docker hub password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d9ac1",
   "metadata": {},
   "source": [
    "Now we can construct the metadata that the chassis service needs to build and publish the container to docker hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = {\n",
    "    'name': f'{username}/chassisml-sklearn-demo:latest',\n",
    "    'version': '0.0.1',\n",
    "    'model_name': 'digits',\n",
    "    'model_path': './mlflow_custom_pyfunc_svm',\n",
    "    'registry_auth': base64.b64encode(f\"{username}:{password}\".encode(\"utf-8\")).decode(\"utf-8\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-failing",
   "metadata": {},
   "source": [
    "### Launch the job\n",
    "\n",
    "Important fields that we should fill in here are:\n",
    "\n",
    "* `image_data`: the values defined above\n",
    "* `base_url`: the name of the service that runs Chassis (that is running in the same k8s cluster that this notebook is running in)\n",
    "* `deploy`: whether to publish this image to Docker Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chassisml.publish(\n",
    "    image_data=image_data,\n",
    "    deploy=True,\n",
    "    base_url='http://chassis:5000'\n",
    ")\n",
    "\n",
    "error = res.get('error')\n",
    "job_id = res.get('job_id')\n",
    "\n",
    "if error:\n",
    "    print('Error:', error)\n",
    "else:\n",
    "    print('Job ID:', job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-arrow",
   "metadata": {},
   "source": [
    "After the request is made, Chassis launches a job that runs Kaniko and builds the docker image based on the values provided.\n",
    "\n",
    "You can get the id of the job created from the result of the request. This id can be used to ask for the status of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "chassisml.get_job_status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15304f",
   "metadata": {},
   "source": [
    "**Poll the job a few times until it's finished.** You can also use `kubectl get pods -A` and `kubectl logs` to watch the build in progress in the testfaster SSH tab.\n",
    "\n",
    "Now, we should be able to see the created image listed in the registry. This means that the service has correctly created the image and uploaded it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-prison",
   "metadata": {},
   "source": [
    "### Pull the docker image\n",
    "\n",
    "Now that the job has finished, we can check that the image has been pushed to [Docker Hub](https://hub.docker.com). Log into Docker Hub and check that the tag has been pushed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6712b9",
   "metadata": {},
   "source": [
    "### (optional) Download the tar file\n",
    "\n",
    "We can also download the docker image that has been generated in the form of a tar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca586ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = './downloaded_image.tar'\n",
    "chassisml.download_tar(job_id, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, FileLink\n",
    "\n",
    "local_file = FileLink(dst, result_html_prefix=\"Click here to download: \")\n",
    "display(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edc228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
